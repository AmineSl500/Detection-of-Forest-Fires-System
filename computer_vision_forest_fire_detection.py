# -*- coding: utf-8 -*-
"""Computer Vision Forest Fire Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bGHRsFLoTwy6ePPARLPF3a95S4g-uQh3
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import skimage.data as data
import skimage.segmentation as seg
import skimage.filters as filters
import skimage.draw as draw
import skimage.color as color
from skimage.color import rgb2gray
import pandas as pd
import numpy as np
import json
import random, string
import seaborn as sns
import matplotlib.pyplot as plt
import cv2
# %matplotlib inline
# Import libraries
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import callbacks
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from lightgbm import LGBMClassifier
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.model_selection import KFold
from sklearn.model_selection import LeaveOneGroupOut
from sklearn.metrics import mean_squared_log_error
from sklearn import svm
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import *
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.impute import SimpleImputer
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error
import math
from tqdm import tqdm_notebook
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import StandardScaler
from sklearn.kernel_ridge import KernelRidge
from sklearn.ensemble import GradientBoostingRegressor
import lightgbm as lgb
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.base import BaseEstimator
from sklearn.base import RegressorMixin
from sklearn.base import TransformerMixin
from sklearn.svm import SVR
from sklearn.linear_model import Ridge, RidgeCV
from mlxtend.regressor import StackingCVRegressor
from sklearn.decomposition import PCA, KernelPCA
from sklearn.model_selection import GridSearchCV
from scipy import stats

import os

from google.colab import drive

drive.mount('/content/drive/')
os.chdir("/content/drive/MyDrive/Colab/Computer Vision/Dataset")

image = cv2.imread('Training and Validation/nofire/nofire_0009.jpg')

print('This image is:', type(image), 
      ' with dimensions:', image.shape)
image_copy = np.copy(image)

# RGB (from BGR)
image_copy = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)

# Display the image copy
plt.imshow(image_copy)

from pylab import gray, imshow, show
import numpy as np
from skimage.color import rgb2xyz
from skimage.color import rgb2xyz
from skimage.color import rgb2rgbcie
from skimage.color import rgb2hsv
# loading image
img = image_copy
 
  
# showing image
print("Image")
imshow(img)
show()
 
# rgb to lab
new_img =rgb2hsv(image_copy)
 
# showing new image
print("New Image")
imshow(new_img)
show()

!pip install SimpleCV

from colormath.color_objects import LabColor, XYZColor
from colormath.color_conversions import convert_color

lab = LabColor(0.903, 16.296, -2.22)
xyz = convert_color(lab, XYZColor)

def anisodiff(img,niter=1,kappa=50,gamma=0.1,step=(1.,1.),option=2,ploton=False):
    """
    Anisotropic diffusion.
 
    Usage:
    imgout = anisodiff(im, niter, kappa, gamma, option)
 
    Arguments:
            img    - input image
            niter  - number of iterations
            kappa  - conduction coefficient 20-100 ?
            gamma  - max value of .25 for stability
            step   - tuple, the distance between adjacent pixels in (y,x)
            option - 1 Perona Malik diffusion equation No 1
                     2 Perona Malik diffusion equation No 2
            ploton - if True, the image will be plotted on every iteration
 
    Returns:
            imgout   - diffused image.
 
    kappa controls conduction as a function of gradient.  If kappa is low
    small intensity gradients are able to block conduction and hence diffusion
    across step edges.  A large value reduces the influence of intensity
    gradients on conduction.
 
    gamma controls speed of diffusion (you usually want it at a maximum of
    0.25)
 
    step is used to scale the gradients in case the spacing between adjacent
    pixels differs in the x and y axes
 
    Diffusion equation 1 favours high contrast edges over low contrast ones.
    Diffusion equation 2 favours wide regions over smaller ones.
 
    Reference: 
    P. Perona and J. Malik. 
    Scale-space and edge detection using ansotropic diffusion.
    IEEE Transactions on Pattern Analysis and Machine Intelligence, 
    12(7):629-639, July 1990.
 
    Original MATLAB code by Peter Kovesi  
    School of Computer Science & Software Engineering
    The University of Western Australia
    pk @ csse uwa edu au
    <http://www.csse.uwa.edu.au>
 
    Translated to Python and optimised by Alistair Muldal
    Department of Pharmacology
    University of Oxford
    <alistair.muldal@pharm.ox.ac.uk>
 
    June 2000  original version.       
    March 2002 corrected diffusion eqn No 2.
    July 2012 translated to Python
    """
 
    # ...you could always diffuse each color channel independently if you
    # really want
    if img.ndim == 3:
        warnings.warn("Only grayscale images allowed, converting to 2D matrix")
        img = img.mean(2)
 
    # initialize output array
    img = img.astype('float32')
    imgout = img.copy()
 
    # initialize some internal variables
    deltaS = np.zeros_like(imgout)
    deltaE = deltaS.copy()
    NS = deltaS.copy()
    EW = deltaS.copy()
    gS = np.ones_like(imgout)
    gE = gS.copy()
 
    # create the plot figure, if requested
    if ploton:
        import pylab as pl
        from time import sleep
 
        fig = pl.figure(figsize=(20,5.5),num="Anisotropic diffusion")
        ax1,ax2 = fig.add_subplot(1,2,1),fig.add_subplot(1,2,2)
 
        ax1.imshow(img,interpolation='nearest')
        ih = ax2.imshow(imgout,interpolation='nearest',animated=True)
        ax1.set_title("Original image")
        ax2.set_title("Iteration 0")
 
        fig.canvas.draw()
 
    for ii in range(niter):
 
        # calculate the diffs
        deltaS[:-1,: ] = np.diff(imgout,axis=0)
        deltaE[: ,:-1] = np.diff(imgout,axis=1)
 
        # conduction gradients (only need to compute one per dim!)
        if option == 1:
            gS = np.exp(-(deltaS/kappa)**2.)/step[0]
            gE = np.exp(-(deltaE/kappa)**2.)/step[1]
        elif option == 2:
            gS = 1./(1.+(deltaS/kappa)**2.)/step[0]
            gE = 1./(1.+(deltaE/kappa)**2.)/step[1]
 
        # update matrices
        E = gE*deltaE
        S = gS*deltaS
 
        # subtract a copy that has been shifted 'North/West' by one
        # pixel. don't as questions. just do it. trust me.
        NS[:] = S
        EW[:] = E
        NS[1:,:] -= S[:-1,:]
        EW[:,1:] -= E[:,:-1]
 
        # update the image
        imgout += gamma*(NS+EW)
 
        if ploton:
            iterstring = "Iteration %i" %(ii+1)
            ih.set_data(imgout)
            ax2.set_title(iterstring)
            fig.canvas.draw()
            # sleep(0.01)
 
    return imgout

import warnings
a_image = anisodiff(new_img)
imshow(a_image)
show()

def image_show(image, nrows=1, ncols=1, cmap='gray'):
    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 14))
    ax.imshow(image, cmap='gray')
    ax.axis('off')
    return fig, ax

gray = rgb2gray(new_img)
plt.imshow(gray, cmap='gray')
gray_r = gray.reshape(gray.shape[0]*gray.shape[1])
threshold = np.percentile(gray_r, 90)
for i in range(gray_r.shape[0]):
    if gray_r[i] > threshold:
        gray_r[i] = 1
    else:
        gray_r[i] = 0
gray_new = gray_r.reshape(gray.shape[0],gray.shape[1])
plt.imshow(gray_new, cmap='gray')

"""# Nouvelle section"""

plt.imshow(image, cmap='gray')

from pylab import gray, imshow, show
import numpy as np
from skimage.color import rgb2xyz
from skimage.color import rgb2rgbcie
from skimage.color import rgb2hsv
from skimage.color import rgb2gray
gray = rgb2gray(a_image)
plt.imshow(gray, cmap='gray')
gray_r = gray.reshape(gray.shape[0]*gray.shape[1])
threshold = np.percentile(gray_r, 90)
for i in range(gray_r.shape[0]):
    if gray_r[i] > threshold:
        gray_r[i] = 1
    else:
        gray_r[i] = 0
gray_new = gray_r.reshape(gray.shape[0],gray.shape[1])
plt.imshow(gray_new, cmap='gray')

from google.colab.patches import cv2_imshow

image_blue_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
#plt.imshow(image_blue_hsv)

cv2_imshow(image_blue_hsv)

gray = rgb2gray(image_blue_hsv)
plt.imshow(gray, cmap='gray')
gray_r = gray.reshape(gray.shape[0]*gray.shape[1])
threshold = np.percentile(gray_r, 95)
for i in range(gray_r.shape[0]):
    if gray_r[i] > threshold:
        gray_r[i] = 1
    else:
        gray_r[i] = 0
gray_new = gray_r.reshape(gray.shape[0],gray.shape[1])
plt.imshow(gray_new, cmap='gray')

gray = rgb2gray(image)
gray_r = gray.reshape(gray.shape[0]*gray.shape[1])
for i in range(gray_r.shape[0]):
    if gray_r[i] > gray_r.mean():
        gray_r[i] = 3
    else:
        gray_r[i] = 0
gray = gray_r.reshape(gray.shape[0],gray.shape[1])
plt.imshow(gray, cmap='gray')

pic = image
pic_n = pic.reshape(pic.shape[0]*pic.shape[1], pic.shape[2])
pic_n.shape

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=5, random_state=0).fit(pic_n)
pic2show = kmeans.cluster_centers_[kmeans.labels_]

cluster_pic = pic2show.reshape(pic.shape[0], pic.shape[1], pic.shape[2])
plt.imshow(cluster_pic)





LBP

# import the necessary packages
from skimage import feature
import numpy as np

class LocalBinaryPatterns:
	def __init__(self, numPoints, radius):
		# store the number of points and radius
		self.numPoints = numPoints
		self.radius = radius

	def describe(self, image, eps=1e-7):
		# compute the Local Binary Pattern representation
		# of the image, and then use the LBP representation
		# to build the histogram of patterns
		lbp = feature.local_binary_pattern(image, self.numPoints,
			self.radius, method="uniform")
		(hist, _) = np.histogram(lbp.ravel(),
			bins=np.arange(0, self.numPoints + 3),
			range=(0, self.numPoints + 2))

		# normalize the histogram
		hist = hist.astype("float")
		hist /= (hist.sum() + eps)

		# return the histogram of Local Binary Patterns
		return hist

# import the necessary packages
from sklearn.svm import LinearSVC
from imutils import paths
import cv2
import os

# initialize the local binary patterns descriptor along with
# the data and label lists
desc = LocalBinaryPatterns(24, 8)
data = []
labels = []

# loop over the training images
for imagePath in paths.list_images("/content/drive/MyDrive/Colab/Computer Vision/Dataset/Training and Validation/fire"):
	# load the image, convert it to grayscale, and describe it
	image = cv2.imread(imagePath)
	gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
	hist = desc.describe(gray)

	# extract the label from the image path, then update the
	# label and data lists
	labels.append('fire')
	data.append([hist,describe_hog(hog_feature(image))])

from matplotlib import pyplot as plt
print(hist)
print (labels)
plt.imshow(image)
plt.show()

# loop over the training images
for imagePath in paths.list_images("/content/drive/MyDrive/Colab/Computer Vision/Dataset/Training and Validation/nofire"):
	# load the image, convert it to grayscale, and describe it
	image = cv2.imread(imagePath)
	gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
	hist = desc.describe(gray)

	# extract the label from the image path, then update the
	# label and data lists
	labels.append('nofire')
	data.append([hist,describe_hog(hog_feature(image))])

from matplotlib import pyplot as plt
print(hist)
print (labels)
plt.imshow(image)
plt.show()

# train a Linear SVM on the data
from sklearn.neighbors import KNeighborsClassifier

#model = KNeighborsClassifier(n_neighbors=1)
model = LinearSVC(C=100.0, random_state=42)
model.fit(data, labels)

predictions = []

# loop over the testing images
for imagePath in paths.list_images("/content/drive/MyDrive/Colab/Computer Vision/Dataset/Testing/fire"):
  # load the image, convert it to grayscale, describe it,
  # and classify it
  image = cv2.imread(imagePath)
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  hist = desc.describe(gray)
  prediction = model.predict(hist.reshape(1, -1))
  predictions.append(prediction)
  cv2.putText(image, prediction[0], (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
  plt.imshow(image)

true = []
for i in predictions:
  if(i == 'fire'):
    true.append(1)
  else:
    true.append(0)
print(true)
print(sum(true)/len(true))

predictions= []

# loop over the testing images
for imagePath in paths.list_images("/content/drive/MyDrive/Colab/Computer Vision/Dataset/Testing/nofire"):
  # load the image, convert it to grayscale, describe it,
  # and classify it
  image = cv2.imread(imagePath)
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  hist = desc.describe(gray)
  prediction = model.predict(hist.reshape(1, -1))
  predictions.append(prediction)
  cv2.putText(image, prediction[0], (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
  plt.imshow(image)

true = []
for i in predictions:
  if(i == 'nofire'):
    true.append(1)
  else:
    true.append(0)
print(true)
print(sum(true)/len(true))

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

def hsvfunction (h_min1, h_max1, s_min1, s_max1, v_min1, v_max1 ):
  lower = np.array([h_min1, s_min1, v_min1])
  upper = np.array([h_max1, s_max1, v_max1])
  return lower, upper

def corefunction(path):
  img = cv2.imread('Training and Validation/fire/fire_0005.jpg')
  cv2_imshow(img)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
  lower, upper = hsvfunction(0, 74, 200, 20, 170, 235) # mask i found due to a research
  mask1 = cv2.inRange(imgHSV, lower, upper)
  lower2, upper2 = hsvfunction(0, 179, 0, 199, 236, 255) # mask i found while trying in low lighting pic
  mask2 = cv2.inRange(imgHSV, lower2, upper2)
  lower3, upper3 = hsvfunction(0, 19, 70, 255, 60, 255) ## mask i found while trying in good lighting pic
  mask3 = cv2.inRange(imgHSV, lower3, upper3)
  imgResult1 = cv2.bitwise_and(img, img, mask=mask1)
  imgResult2 = cv2.bitwise_and(img, img, mask=mask2)
  imgResult3 = cv2.bitwise_and(img, img, mask=mask3)
  mask_fin=cv2.bitwise_or(mask2, mask3, mask=None)
  mask_fin = cv2.bitwise_or(mask1, mask_fin, mask=None)
  img_final = cv2.bitwise_and(img, img, mask=mask_fin)
  L=[img, imgHSV, mask1 ,imgResult1 ,mask2 ,imgResult2 ,mask3 ,imgResult3, mask_fin, img_final]
  # create figure
  fig = plt.figure(figsize=(10, 7))
  
  # setting values to rows and column variables
  rows = 5
  columns = 2
  
  fig.add_subplot(rows, columns, 1)
  plt.imshow(img)
  fig.add_subplot(rows, columns, 2)
  plt.imshow(imgHSV)
  fig.add_subplot(rows, columns, 3)
  plt.imshow(mask1)
  fig.add_subplot(rows, columns, 4)
  plt.imshow(imgResult1)
  fig.add_subplot(rows, columns, 5)
  plt.imshow(mask2)
  fig.add_subplot(rows, columns, 6)
  plt.imshow(imgResult2)
  fig.add_subplot(rows, columns, 7)
  plt.imshow(mask3)
  fig.add_subplot(rows, columns, 8)
  plt.imshow(imgResult3)
  fig.add_subplot(rows, columns, 9)
  plt.imshow(mask_fin)
  fig.add_subplot(rows, columns, 10)
  plt.imshow(img_final)
corefunction(path)

path = 'Training and Validation/nofire/nofire_0009.jpg'
img = cv2.imread('Training and Validation/nofire/nofire_0009.jpg')
print(img)
cv2_imshow(img)



















def hog_feature(image_copy):
  from skimage.io import imread
  from skimage.transform import resize
  from skimage.feature import hog
  from skimage import exposure
  import matplotlib.pyplot as plt
  import math
  from skimage.transform import resize
  image = resize(color.rgb2gray(image_copy), (128, 64))
  img = np.array(image)
  mag = []
  theta = []
  for i in range(128):
    magnitudeArray = []
    angleArray = []
    for j in range(64):
      # Condition for axis 0
      if j-1 <= 0 or j+1 >= 64:
        if j-1 <= 0:
          # Condition if first element
          Gx = img[i][j+1] - 0
        elif j + 1 >= len(img[0]):
          Gx = 0 - img[i][j-1]
      # Condition for first element
      else:
        Gx = img[i][j+1] - img[i][j-1]
    
      # Condition for axis 1
      if i-1 <= 0 or i+1 >= 128:
        if i-1 <= 0:
          Gy = 0 - img[i+1][j]
        elif i +1 >= 128:
          Gy = img[i-1][j] - 0
      else:
        Gy = img[i-1][j] - img[i+1][j]

      # Calculating magnitude
      magnitude = math.sqrt(math.pow(Gx, 2) + math.pow(Gy, 2))
      magnitudeArray.append(round(magnitude, 9))

      # Calculating angle
      if Gx == 0:
        angle = math.degrees(0.0)
      else:
        angle = math.degrees(abs(math.atan(Gy / Gx)))
      angleArray.append(round(angle, 9))
    mag.append(magnitudeArray)
    theta.append(angleArray)
  mag = np.array(mag)
  theta = np.array(theta)
  number_of_bins = 9
  step_size = 180 / number_of_bins
  def calculate_j(angle):
    temp = (angle / step_size) - 0.5
    j = math.floor(temp)
    return j
  def calculate_Cj(j):
    Cj = step_size * (j + 0.5)
    return round(Cj, 9)
  def calculate_value_j(magnitude, angle, j):
    Cj = calculate_Cj(j+1)
    Vj = magnitude * ((Cj - angle) / step_size)
    return round(Vj, 9)
  histogram_points_nine = []
  for i in range(0, 128, 8):
    temp = []
    for j in range(0, 64, 8):
      magnitude_values = [[mag[i][x] for x in range(j, j+8)] for i in range(i,i+8)]
      angle_values = [[theta[i][x] for x in range(j, j+8)] for i in range(i, i+8)]
      for k in range(len(magnitude_values)):
        for l in range(len(magnitude_values[0])):
          bins = [0.0 for _ in range(number_of_bins)]
          value_j = calculate_j(angle_values[k][l])
          Vj = calculate_value_j(magnitude_values[k][l], angle_values[k][l], value_j)
          Vj_1 = magnitude_values[k][l] - Vj
          bins[value_j]+=Vj
          bins[value_j+1]+=Vj_1
          bins = [round(x, 9) for x in bins]
      temp.append(bins)
    histogram_points_nine.append(temp)
  epsilon = 1e-05
  feature_vectors = []
  for i in range(0, len(histogram_points_nine) - 1, 1):
    temp = []
    for j in range(0, len(histogram_points_nine[0]) - 1, 1):
      values = [[histogram_points_nine[i][x] for x in range(j, j+2)] for i in range(i, i+2)]
      final_vector = []
      for k in values:
        for l in k:
          for m in l:
            final_vector.append(m)
      k = round(math.sqrt(sum([pow(x, 2) for x in final_vector])), 9)
      final_vector = [round(x/(k + epsilon), 9) for x in final_vector]
      temp.append(final_vector)
    feature_vectors.append(temp)
  img = image_copy
  resized_img = resize(img, (128*4, 64*4))
  fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),
                	cells_per_block=(2, 2), visualize=True, multichannel=True)
  return hog_image

l = hog_feature(image_copy)
print(l)
plt.imshow(hog_feature(image_copy), cmap="gray")

def describe_hog(image, eps=1e-7):
		# compute the Local Binary Pattern representation
		# of the image, and then use the LBP representation
		# to build the histogram of patterns
		lbp = feature.local_binary_pattern(image,  8*3, 3, method="uniform")
		(hist, _) = np.histogram(lbp.ravel(),
			bins=np.arange(0, 8*3+ 3),
			range=(0, 8*3 + 2))

		# normalize the histogram
		hist = hist.astype("float")
		hist /= (hist.sum() + eps)

		# return the histogram of Local Binary Patterns
		return hist